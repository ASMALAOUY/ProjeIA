{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a49615c7-e3fe-40a1-9271-0d86ce533d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "1. EXPLORATORY DATA ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Dataset Shape: (13608, 20)\n",
      "\n",
      "First few rows:\n",
      "        id                                              title  \\\n",
      "0   762616  The Complete SQL Bootcamp 2020: Go from Zero t...   \n",
      "1   937678  Tableau 2020 A-Z: Hands-On Tableau Training fo...   \n",
      "2  1361790             PMP Exam Prep Seminar -  PMBOK Guide 6   \n",
      "3   648826         The Complete Financial Analyst Course 2020   \n",
      "4   637930  An Entire MBA in 1 Course:Award Winning Busine...   \n",
      "\n",
      "                                                 url  is_paid  \\\n",
      "0                 /course/the-complete-sql-bootcamp/     True   \n",
      "1                                 /course/tableau10/     True   \n",
      "2                        /course/pmp-pmbok6-35-pdus/     True   \n",
      "3     /course/the-complete-financial-analyst-course/     True   \n",
      "4  /course/an-entire-mba-in-1-courseaward-winning...     True   \n",
      "\n",
      "   num_subscribers  avg_rating  avg_rating_recent   rating  num_reviews  \\\n",
      "0           295509     4.66019            4.67874  4.67874        78006   \n",
      "1           209070     4.58956            4.60015  4.60015        54581   \n",
      "2           155282     4.59491            4.59326  4.59326        52653   \n",
      "3           245860     4.54407            4.53772  4.53772        46447   \n",
      "4           374836     4.47080            4.47173  4.47173        41630   \n",
      "\n",
      "   is_wishlisted  num_published_lectures  num_published_practice_tests  \\\n",
      "0          False                      84                             0   \n",
      "1          False                      78                             0   \n",
      "2          False                     292                             2   \n",
      "3          False                     338                             0   \n",
      "4          False                      83                             0   \n",
      "\n",
      "                created        published_time  discount_price__amount  \\\n",
      "0  2016-02-14T22:57:48Z  2016-04-06T05:16:11Z                   455.0   \n",
      "1  2016-08-22T12:10:18Z  2016-08-23T16:59:49Z                   455.0   \n",
      "2  2017-09-26T16:32:48Z  2017-11-14T23:58:14Z                   455.0   \n",
      "3  2015-10-23T13:34:35Z  2016-01-21T01:38:48Z                   455.0   \n",
      "4  2015-10-12T06:39:46Z  2016-01-11T21:39:33Z                   455.0   \n",
      "\n",
      "  discount_price__currency discount_price__price_string  price_detail__amount  \\\n",
      "0                      INR                         ₹455                8640.0   \n",
      "1                      INR                         ₹455                8640.0   \n",
      "2                      INR                         ₹455                8640.0   \n",
      "3                      INR                         ₹455                8640.0   \n",
      "4                      INR                         ₹455                8640.0   \n",
      "\n",
      "  price_detail__currency price_detail__price_string  \n",
      "0                    INR                     ₹8,640  \n",
      "1                    INR                     ₹8,640  \n",
      "2                    INR                     ₹8,640  \n",
      "3                    INR                     ₹8,640  \n",
      "4                    INR                     ₹8,640  \n",
      "\n",
      "Data Types:\n",
      "id                                int64\n",
      "title                            object\n",
      "url                              object\n",
      "is_paid                            bool\n",
      "num_subscribers                   int64\n",
      "avg_rating                      float64\n",
      "avg_rating_recent               float64\n",
      "rating                          float64\n",
      "num_reviews                       int64\n",
      "is_wishlisted                      bool\n",
      "num_published_lectures            int64\n",
      "num_published_practice_tests      int64\n",
      "created                          object\n",
      "published_time                   object\n",
      "discount_price__amount          float64\n",
      "discount_price__currency         object\n",
      "discount_price__price_string     object\n",
      "price_detail__amount            float64\n",
      "price_detail__currency           object\n",
      "price_detail__price_string       object\n",
      "dtype: object\n",
      "\n",
      "Basic Statistics:\n",
      "                 id  num_subscribers    avg_rating  avg_rating_recent  \\\n",
      "count  1.360800e+04     13608.000000  13608.000000       13608.000000   \n",
      "mean   1.681721e+06      2847.010435      3.923293           3.912242   \n",
      "std    9.539271e+05      9437.865634      1.031304           1.039237   \n",
      "min    2.762000e+03         0.000000      0.000000           0.000000   \n",
      "25%    8.580862e+05        62.000000      3.800000           3.787315   \n",
      "50%    1.623421e+06       533.000000      4.194440           4.181735   \n",
      "75%    2.503720e+06      2279.500000      4.450000           4.452105   \n",
      "max    3.486006e+06    374836.000000      5.000000           5.000000   \n",
      "\n",
      "             rating   num_reviews  num_published_lectures  \\\n",
      "count  13608.000000  13608.000000            13608.000000   \n",
      "mean       3.912242    243.169827               32.224794   \n",
      "std        1.039237   1580.965895               42.766911   \n",
      "min        0.000000      0.000000                0.000000   \n",
      "25%        3.787315      7.000000               12.000000   \n",
      "50%        4.181735     24.000000               21.000000   \n",
      "75%        4.452105     87.000000               37.000000   \n",
      "max        5.000000  78006.000000              699.000000   \n",
      "\n",
      "       num_published_practice_tests  discount_price__amount  \\\n",
      "count                  13608.000000            12205.000000   \n",
      "mean                       0.110523              493.943794   \n",
      "std                        0.623501              267.827260   \n",
      "min                        0.000000              455.000000   \n",
      "25%                        0.000000              455.000000   \n",
      "50%                        0.000000              455.000000   \n",
      "75%                        0.000000              455.000000   \n",
      "max                        6.000000             3200.000000   \n",
      "\n",
      "       price_detail__amount  \n",
      "count          13111.000000  \n",
      "mean            4646.992602  \n",
      "std             3109.101019  \n",
      "min             1280.000000  \n",
      "25%             1600.000000  \n",
      "50%             3200.000000  \n",
      "75%             8640.000000  \n",
      "max            12800.000000  \n",
      "\n",
      "================================================================================\n",
      "2. MISSING VALUES ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Missing Values:\n",
      "                                                    Column  Missing_Count  \\\n",
      "discount_price__amount              discount_price__amount           1403   \n",
      "discount_price__currency          discount_price__currency           1403   \n",
      "discount_price__price_string  discount_price__price_string           1403   \n",
      "price_detail__amount                  price_detail__amount            497   \n",
      "price_detail__currency              price_detail__currency            497   \n",
      "price_detail__price_string      price_detail__price_string            497   \n",
      "\n",
      "                              Missing_Percentage  \n",
      "discount_price__amount                     10.31  \n",
      "discount_price__currency                   10.31  \n",
      "discount_price__price_string               10.31  \n",
      "price_detail__amount                        3.65  \n",
      "price_detail__currency                      3.65  \n",
      "price_detail__price_string                  3.65  \n",
      "\n",
      "================================================================================\n",
      "3. OUTLIERS DETECTION & HANDLING\n",
      "================================================================================\n",
      "\n",
      "num_subscribers: 1614 outliers detected (11.86%)\n",
      "\n",
      "avg_rating: 944 outliers detected (6.94%)\n",
      "\n",
      "avg_rating_recent: 982 outliers detected (7.22%)\n",
      "\n",
      "rating: 982 outliers detected (7.22%)\n",
      "\n",
      "num_reviews: 1978 outliers detected (14.54%)\n",
      "\n",
      "num_published_lectures: 989 outliers detected (7.27%)\n",
      "\n",
      "num_published_practice_tests: 600 outliers detected (4.41%)\n",
      "\n",
      "discount_price__amount: 795 outliers detected (5.84%)\n",
      "Removed 1453 rows for num_reviews\n",
      "Removed 832 rows for num_subscribers\n",
      "Removed 328 rows for num_published_lectures\n",
      "\n",
      "Dataset shape after outlier removal: (10995, 20)\n",
      "\n",
      "================================================================================\n",
      "4. FEATURE ENGINEERING\n",
      "================================================================================\n",
      "\n",
      "✓ Created temporal features: course_age_days, course_year, course_month\n",
      "✓ Created: review_rate (reviews per subscriber)\n",
      "✓ Created: is_highly_rated, rating_category\n",
      "✓ Created: popularity_score (normalized)\n",
      "✓ Created: content_density (lectures per day)\n",
      "✓ Created: wishlist_flag\n",
      "\n",
      "================================================================================\n",
      "5. FINAL DATA VALIDATION\n",
      "================================================================================\n",
      "\n",
      "Final dataset shape: (10995, 29)\n",
      "Rows removed: 2613\n",
      "\n",
      "New features created:\n",
      "  - content_density\n",
      "  - course_age_days\n",
      "  - course_month\n",
      "  - course_year\n",
      "  - is_highly_rated\n",
      "  - popularity_score\n",
      "  - rating_category\n",
      "  - review_rate\n",
      "  - wishlist_flag\n",
      "\n",
      "Remaining missing values: 5240\n",
      "Duplicate rows: 0\n",
      "\n",
      "Final dataset info:\n",
      "id                                            int64\n",
      "title                                        object\n",
      "url                                          object\n",
      "is_paid                                        bool\n",
      "num_subscribers                               int64\n",
      "avg_rating                                  float64\n",
      "avg_rating_recent                           float64\n",
      "rating                                      float64\n",
      "num_reviews                                   int64\n",
      "is_wishlisted                                  bool\n",
      "num_published_lectures                        int64\n",
      "num_published_practice_tests                  int64\n",
      "created                         datetime64[ns, UTC]\n",
      "published_time                  datetime64[ns, UTC]\n",
      "discount_price__amount                      float64\n",
      "discount_price__currency                     object\n",
      "discount_price__price_string                 object\n",
      "price_detail__amount                        float64\n",
      "price_detail__currency                       object\n",
      "price_detail__price_string                   object\n",
      "course_age_days                               int64\n",
      "course_year                                   int32\n",
      "course_month                                  int32\n",
      "review_rate                                 float64\n",
      "is_highly_rated                               int64\n",
      "rating_category                            category\n",
      "popularity_score                            float64\n",
      "content_density                             float64\n",
      "wishlist_flag                                 int64\n",
      "dtype: object\n",
      "\n",
      "✓ Cleaned dataset saved to: cousedata_cleaned.csv\n",
      "\n",
      "Sample of engineered features:\n",
      "      wishlist_flag  popularity_score  course_age_days  content_density  \\\n",
      "1190              0          0.210254             2535         0.019322   \n",
      "1192              0          0.252891             3303         0.008172   \n",
      "1199              0          0.364060             3012         0.021241   \n",
      "1200              0          0.702054             2523         0.028130   \n",
      "1201              0          0.389263             4383         0.013002   \n",
      "1202              0          0.166580             3369         0.028783   \n",
      "1204              0          0.245641             2805         0.005346   \n",
      "1205              0          0.573451             3921         0.009434   \n",
      "1206              0          0.570516             3560         0.017130   \n",
      "1208              0          0.254790             2688         0.004835   \n",
      "\n",
      "      course_year  course_month  review_rate rating_category  is_highly_rated  \n",
      "1190         2018            12     0.268253         Average                0  \n",
      "1192         2016            11     0.222374            Good                0  \n",
      "1199         2017             9     0.152607       Excellent                1  \n",
      "1200         2019             1     0.079400            Good                0  \n",
      "1201         2013            12     0.142287       Excellent                1  \n",
      "1202         2016             9     0.334369       Excellent                1  \n",
      "1204         2018             3     0.224719            Good                0  \n",
      "1205         2015             3     0.096299            Good                0  \n",
      "1206         2016             3     0.096794            Good                0  \n",
      "1208         2018             7     0.215301            Good                0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('cousedataset.csv')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"1. EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nDataset Shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nBasic Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# ============================================================================\n",
    "# 2. MISSING VALUES ANALYSIS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"2. MISSING VALUES ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "missing_data = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isnull().sum(),\n",
    "    'Missing_Percentage': (df.isnull().sum() / len(df) * 100).round(2)\n",
    "})\n",
    "missing_data = missing_data[missing_data['Missing_Count'] > 0].sort_values('Missing_Percentage', ascending=False)\n",
    "print(\"\\nMissing Values:\")\n",
    "print(missing_data if len(missing_data) > 0 else \"No missing values found\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. OUTLIERS DETECTION & REMOVAL\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"3. OUTLIERS DETECTION & HANDLING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def detect_outliers_iqr(data, column):\n",
    "    \"\"\"Detect outliers using IQR method\"\"\"\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "\n",
    "# Numeric columns to check for outliers\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "outliers_summary = {}\n",
    "for col in numeric_cols:\n",
    "    outliers = detect_outliers_iqr(df, col)\n",
    "    if len(outliers) > 0:\n",
    "        outliers_summary[col] = len(outliers)\n",
    "        print(f\"\\n{col}: {len(outliers)} outliers detected ({len(outliers)/len(df)*100:.2f}%)\")\n",
    "\n",
    "# Remove extreme outliers (keep rows where all numeric values are within reasonable bounds)\n",
    "df_clean = df.copy()\n",
    "\n",
    "# For rating column: if exists, cap between 0-5\n",
    "if 'rating' in df_clean.columns:\n",
    "    df_clean['rating'] = df_clean['rating'].clip(0, 5)\n",
    "\n",
    "# For subscriber count, reviews, etc.: remove extreme outliers\n",
    "cols_to_check = ['num_reviews', 'num_subscribers', 'num_published_lectures']\n",
    "for col in cols_to_check:\n",
    "    if col in df_clean.columns:\n",
    "        Q1 = df_clean[col].quantile(0.25)\n",
    "        Q3 = df_clean[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 3 * IQR  # Use 3*IQR for removal (more conservative)\n",
    "        upper_bound = Q3 + 3 * IQR\n",
    "        initial_count = len(df_clean)\n",
    "        df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]\n",
    "        print(f\"Removed {initial_count - len(df_clean)} rows for {col}\")\n",
    "\n",
    "print(f\"\\nDataset shape after outlier removal: {df_clean.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. FEATURE ENGINEERING\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"4. FEATURE ENGINEERING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Convert datetime columns if they exist\n",
    "date_cols = ['created', 'published_time']\n",
    "for col in date_cols:\n",
    "    if col in df_clean.columns:\n",
    "        df_clean[col] = pd.to_datetime(df_clean[col], errors='coerce')\n",
    "\n",
    "# Extract temporal features from created date\n",
    "if 'created' in df_clean.columns:\n",
    "    # Handle timezone-aware/naive datetime conversion\n",
    "    now = pd.Timestamp.now(tz='UTC')\n",
    "    if df_clean['created'].dt.tz is None:\n",
    "        # If naive, use naive now\n",
    "        now = datetime.now()\n",
    "    df_clean['course_age_days'] = (now - df_clean['created']).dt.days\n",
    "    df_clean['course_year'] = df_clean['created'].dt.year\n",
    "    df_clean['course_month'] = df_clean['created'].dt.month\n",
    "    print(\"\\n✓ Created temporal features: course_age_days, course_year, course_month\")\n",
    "\n",
    "# Engagement metrics\n",
    "if 'num_reviews' in df_clean.columns and 'num_subscribers' in df_clean.columns:\n",
    "    df_clean['review_rate'] = df_clean['num_reviews'] / (df_clean['num_subscribers'] + 1)\n",
    "    df_clean['review_rate'] = df_clean['review_rate'].clip(0, 1)  # Cap at 100%\n",
    "    print(\"✓ Created: review_rate (reviews per subscriber)\")\n",
    "\n",
    "# Rating-based features\n",
    "if 'rating' in df_clean.columns:\n",
    "    df_clean['is_highly_rated'] = (df_clean['rating'] >= 4.5).astype(int)\n",
    "    df_clean['rating_category'] = pd.cut(df_clean['rating'], \n",
    "                                         bins=[0, 3, 4, 4.5, 5], \n",
    "                                         labels=['Poor', 'Average', 'Good', 'Excellent'])\n",
    "    print(\"✓ Created: is_highly_rated, rating_category\")\n",
    "\n",
    "# Course popularity score (composite metric)\n",
    "if 'num_subscribers' in df_clean.columns:\n",
    "    scaler = MinMaxScaler()\n",
    "    df_clean['popularity_score'] = scaler.fit_transform(\n",
    "        df_clean[['num_subscribers']]\n",
    "    )\n",
    "    print(\"✓ Created: popularity_score (normalized)\")\n",
    "\n",
    "# Price-related features\n",
    "if 'discount_price_amount' in df_clean.columns:\n",
    "    df_clean['has_discount'] = (df_clean['discount_price_amount'] > 0).astype(int)\n",
    "    print(\"✓ Created: has_discount\")\n",
    "\n",
    "# Content features\n",
    "if 'num_published_lectures' in df_clean.columns:\n",
    "    df_clean['content_density'] = df_clean['num_published_lectures'] / (df_clean['course_age_days'] + 1)\n",
    "    print(\"✓ Created: content_density (lectures per day)\")\n",
    "\n",
    "# Wishlist engagement\n",
    "if 'is_wishlisted' in df_clean.columns:\n",
    "    df_clean['wishlist_flag'] = df_clean['is_wishlisted'].astype(int)\n",
    "    print(\"✓ Created: wishlist_flag\")\n",
    "\n",
    "# ============================================================================\n",
    "# 5. DATA VALIDATION & SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"5. FINAL DATA VALIDATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nFinal dataset shape: {df_clean.shape}\")\n",
    "print(f\"Rows removed: {len(df) - len(df_clean)}\")\n",
    "print(f\"\\nNew features created:\")\n",
    "new_cols = set(df_clean.columns) - set(df.columns)\n",
    "for col in sorted(new_cols):\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "# Check for any remaining issues\n",
    "print(f\"\\nRemaining missing values: {df_clean.isnull().sum().sum()}\")\n",
    "print(f\"Duplicate rows: {df_clean.duplicated().sum()}\")\n",
    "\n",
    "# Display cleaned dataset info\n",
    "print(\"\\nFinal dataset info:\")\n",
    "print(df_clean.dtypes)\n",
    "\n",
    "# ============================================================================\n",
    "# 6. SAVE CLEANED DATASET\n",
    "# ============================================================================\n",
    "output_file = 'cousedata_cleaned.csv'\n",
    "df_clean.to_csv(output_file, index=False)\n",
    "print(f\"\\n✓ Cleaned dataset saved to: {output_file}\")\n",
    "\n",
    "# Display sample of engineered features\n",
    "print(\"\\nSample of engineered features:\")\n",
    "feature_cols = list(new_cols)\n",
    "if feature_cols:\n",
    "    print(df_clean[feature_cols].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfc06b9-216e-4c19-8343-6048da965a87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
